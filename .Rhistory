x=rnorm(10)
x
NA
! NA
class(NA)
?class
set.seed(0)
rnorm(10)
?data.frame
d = data.frame(lower=numeric(100),mean=numeric(100),upper=numeric(100))
?numeric
View(d)
for (i in 1:100) {}
for (i in 1:100) {x = rnorm(10000); d[i,] = mean(x) + c(1.96, 0, 1.96) * sd(x) / sqrt(length(x))}
length(d$lower>0)
length(d$lower>0 | d$upper<0)
?dbinom
probs = dbinom(1:20, 20, prob = 0.25)
probs>10
probs
probs[11:21]
probs[11:20]
sum(probs[11:20])
?pbinom
?rbinom
rbinom(10,20,0.25)
hist(rbinom(1000000,20,0.25))
hist(rbinom(1000000,20,0.1))
hist(rbinom(1000000,20,0.2))
hist(rbinom(1000000,20,0.5))
hist(rbinom(1000000,20,0.8))
hist(rbinom(1000000,20,0.5))
hist(rbinom(1000000,200,0.05))
?rpois
0.02/(e^(-80/60))
0.02/(exp(1)^(-80/60))
0.02*(exp(1)^(-80/60))
0.02*(exp(1)^(80/61.5))
61-94+126-8-24-64-24
ï¼Ÿdnorm
dnorm
?dnorm
x = rnorm(10,mean=5)
y = rnorm(12,mean=6)
t.test(x,y)
?t.test
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
summary(cars)
d1=rnorm(10)
d2=rnorm(10)
set.seed(42)
d1=rnorm(10)
d2=rnorm(10)
t.test(d1,d2)
val = t.test(d1,d2)
t.test(d1,d2)['p.value']
t.test(d1,d2)[['p.value']]
set.seed(42)
N = 10000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
type1_err = type1_err+1
}
}
type1_err_rate = type1_err/N
print(type1_err_rate)
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
type1_err = type1_err+1
}
}
type1_err_rate = type1_err/N
print(type1_err_rate)
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
type1_err = type1_err+1
}
}
type1_err_rate = type1_err/N
cat('Type I Error Rate after',N,'stimulations:',type1_err_rate)
format(N,big.mark=",", )
format(as.numeric(N),big.mark=",", )
format(as.numeric(N),big.mark=",")
format(as.numeric(N))
?format
format(N,big.mark = ',')
format(c(N),big.mark = ',')
scales::label_comma()(N)
formatC(N,big.mark = ',')
type(N)
class(n)
class(N)
format(round(as.numeric(1000.64), 1), nsmall=1, big.mark=",")
format(round(1000), nsmall=1, big.mark=",")
format(round(1000), big.mark=",")
format(round(N), big.mark=",")
format(as.integer(N), big.mark=",")
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
type1_err = type1_err+1
}
}
type1_err_rate = type1_err/N
cat('Type I Error Rate after',format(as.integer(N), big.mark=","),'stimulations:',type1_err_rate)
d3 = d1+rnorm(10)
d3 = c(d1,rnorm(10))
d3
d1
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat(type1_err_rate)
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval < alpha){
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval = t.test(data.test.new, data.control.new)[['p.value']]
}
if (pval < alpha){
type1_err = type1_err+1
}
}
type1_err_rate = type1_err/N
cat(type1_err_rate)
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat(type1_err_rate)
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat('Under the lab protocol, the Type I Error Rate after',format(as.integer(N), big.mark=","),'stimulations is',type1_err_rate,'which is close to',(type1_err_rate-0.04776)/type1_err_rate * 100, '%.')
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat('Under the lab protocol, the Type I Error Rate after',format(as.integer(N), big.mark=","),'stimulations is',type1_err_rate,'which is close to',(type1_err_rate-0.04776)/0.04776 * 100, '%.')
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat('Under the lab protocol, the Type I Error Rate after',format(as.integer(N), big.mark=","),'stimulations is',type1_err_rate,'which is close to',round((type1_err_rate-0.04776)/0.04776 * 100), '% increase.')
set.seed(42)
N = 100000 # number of stimulation
alpha = 0.05 # statistical significance threshold
type1_err = 0 # count of Type I Error
for (i in 1:N) {
data.test = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
data.control = rnorm(n = 10) # draw 10 mice observations from normal distribution for compound test group
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10)) # draw additional 10 mice observations
data.control.new = c(data.control, rnorm(n = 10)) # draw additional 10 mice observations
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new < alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
cat('Under the lab protocol, the Type I Error Rate after',format(as.integer(N), big.mark=","),'stimulations is',type1_err_rate,'which is close to',round((type1_err_rate-0.04776)/0.04776 * 100), '% increase.\n')
cat('In this case, when a Type I Error is committed, we reject the null hypothesis that the difference between means of test group and control group is 0, which means the drug may be "effective". So with this protocol,',type1_err_rate*100,'% of time this lab will conclude that ineffective compounds have an effect.\n')
alpha_list = c(0.05,0.045,0.04,0.035,0.03,0.025,0.02)
get_Type_I_Error_Rate=function(alpha){
set.seed(42)
N = 100000
alpha = alpha
type1_err = 0
for (i in 1:N) {
data.test = rnorm(n = 10)
data.control = rnorm(n = 10)
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10))
data.control.new = c(data.control, rnorm(n = 10))
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new <= alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
return(type1_err_rate)
}
alpha_hat = 0; TER_hat = 0
for (alpha in alpha_list){
TER = get_Type_I_Error_Rate(alpha)
if(TER <= 0.05){
alpha_hat = alpha
TER_hat = TER
break
}
}
cat('Alpha should be equal or smaller than',alpha_hat,'of which the Type I error rate is',TER_hat,'to maintain an overall Type I error rate of 5% under the lab protocol.')
seq(.4,.1,by=0.01)
seq(.4,.1,by=-0.01)
alpha_list = seq(.35,.1,by=-0.01) # set an arbitrary range of list of alphas
get_Type_I_Error_Rate=function(alpha){
set.seed(42)
N = 100000
alpha = alpha
type1_err = 0
for (i in 1:N) {
data.test = rnorm(n = 10)
data.control = rnorm(n = 10)
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10))
data.control.new = c(data.control, rnorm(n = 10))
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new <= alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
return(type1_err_rate)
}
alpha_hat = 0; TER_hat = 0
for (alpha in alpha_list){
TER = get_Type_I_Error_Rate(alpha)
if(TER <= 0.05){
alpha_hat = alpha
TER_hat = TER
break
}
}
cat('Alpha should be equal or smaller than',alpha_hat,', of which the Type I error rate is',TER_hat,', to maintain an overall Type I error rate of 5% under the lab protocol.')
seq(.35,.1,by=-0.01)
alpha_list = seq(.035,.1,by=-0.001) # set an arbitrary range of list of alphas
alpha_list = seq(.035,.01,by=-0.001) # set an arbitrary range of list of alphas
get_Type_I_Error_Rate=function(alpha){
set.seed(42)
N = 100000
alpha = alpha
type1_err = 0
for (i in 1:N) {
data.test = rnorm(n = 10)
data.control = rnorm(n = 10)
pval = t.test(data.test, data.control)[['p.value']]
if (pval <= alpha){
type1_err = type1_err+1
}else{
data.test.new = c(data.test, rnorm(n = 10))
data.control.new = c(data.control, rnorm(n = 10))
pval_new = t.test(data.test.new, data.control.new)[['p.value']]
if (pval_new <= alpha){
type1_err = type1_err+1
}
}
}
type1_err_rate = type1_err/N
return(type1_err_rate)
}
alpha_hat = 0; TER_hat = 0
for (alpha in alpha_list){
TER = get_Type_I_Error_Rate(alpha)
if(TER <= 0.05){
alpha_hat = alpha
TER_hat = TER
break
}
}
cat('Alpha should be equal or smaller than',alpha_hat,', of which the Type I error rate is',TER_hat,', to maintain an overall Type I error rate of 5% under the lab protocol.')
1-dbinom(0,20,0.05)
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/')
suppressMessages(require(ggplot2))
install.packages('ggplot2')
in_file='results/2023-10-03/test_transfer/losses.csv'
dplot=read.csv(infile)
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(ggplot2))
infile='results/2023-10-03/test_transfer/losses.csv'
dplot=read.csv(infile)
View(dplot)
ggplot(data=dplot, aes(x=step, y=loss)) +
geom_line()+
geom_point()
install.packages("reshape2")
ggplot(data=dplot, aes(x=step, y=loss)) +
geom_line()
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(ggplot2))
data=read.csv('data/drug/rep-gdsc-ctd2-mean-log.csv')
View(data)
colnames(data)
data_target=data[,c('Drug.Name','ccle','drug_id','sample_id',
grep(paste0('log_',target,'_published_auc_mean'),colnames(data)))]
target='GDSC'
data_target=data[,c('Drug.Name','ccle','drug_id','sample_id',
grep(paste0('log_',target,'_published_auc_mean'),colnames(data)))]
grep(paste0('log_',target,'_published_auc_mean'),colnames(data))
data_target=data[,c('Drug.Name','ccle','drug_id','sample_id',
colnames(data)[grep(paste0('log_',target,'_published_auc_mean'),colnames(data))])]
View(data_target)
install.packages('dplyr')
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
suppressMessages(require(ggplot2))
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(dplyr))
target='GDSC'
data_in=read.csv('data/drug/rep-gdsc-ctd2-mean-log.csv')
data_in=data_in[,c('Drug.Name','ccle','drug_id','sample_id',
colnames(data_in)[grep(paste0('log_',target,'_published_auc_mean'),colnames(data_in))])]
id_cols=data_in[,c('Drug.Name','ccle','drug_id','sample_id')]
name(data_out_train)
data_out_train=read.csv('results/2023-10-03/test_transfer/train_predictions.csv')
name(data_out_train)
names(data_out_train)
View(id_cols)
View(data_out_train)
len(unique(data_out_train$sample_ids))
length(unique(data_out_train$sample_ids))
length(unique(data_out_train$drug_ids))
length(unique(data_out_train$drug_id))
range(data_out_train$predictions)
View(data_in)
length(unique(data_in$drug_id))
length(unique(data_in$sample_id))
names(data_out_train)
colnames(data_out_train)[2]='sample_id'
data_out_train.2=left_join(data_out_train,id_cols,by=c('sample_id','drug_id'))
View(data_out_train.2)
data_out_test=read.csv('results/2023-10-03/test_transfer/test_predictions.csv')
colnames(data_out_test)[2]='sample_id'
data_out_test.2=left_join(data_out_test,id_cols,by=c('sample_id','drug_id'))
13270+3318
View(data_out_test.2)
View(data_in)
data_in=read.csv('data/drug/rep-gdsc-ctd2-mean-log.csv')
View(data_in)
index=paste0(data_in[,c('Drug.Name','ccle','drug_id','sample_id')])
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(ggplot2))
suppressMessages(require(dplyr))
target='GDSC'
data_in=read.csv('data/drug/rep-gdsc-ctd2-mean-log.csv')
data_in=data_in[,c('Drug.Name','ccle','drug_id','sample_id',
colnames(data_in)[grep(paste0('log_',target,'_published_auc_mean'),colnames(data_in))])]
id_cols=data_in[,c('Drug.Name','ccle','drug_id','sample_id')]
data_out_train=read.csv('results/2023-10-03/test_transfer/train_predictions.csv')
colnames(data_out_train)[2]='sample_id'
data_out_train=left_join(data_out_train,id_cols,by=c('sample_id','drug_id'))
data_out_test=read.csv('results/2023-10-03/test_transfer/test_predictions.csv')
colnames(data_out_test)[2]='sample_id'
data_out_test=left_join(data_out_test,id_cols,by=c('sample_id','drug_id'))
data_out=rbind(data_out_train,data_out_test);rownames(data_out)=paste0(data_out$drug_id,'_',data_out$sample_id)
data_out=data_out[paste0(data_in$drug_id,'_',data_in$sample_id),]
identical(paste0(data_out$drug_id,'_',data_out$sample_id),paste0(data_in$drug_id,'_',data_in$sample_id))
View(data_out)
data_out=data_out[,c('Drug.Name','ccle','drug_id','sample_id','predictions')]
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(ggplot2))
dplot=read.csv('scratch/losses.csv')
ggplot(data=dplot, aes(x=step, y=loss)) +
geom_line()+
geom_point()
ggplot(data=dplot, aes(x=step, y=loss)) +
geom_line()
setwd('/Users/jinrui.liu/Desktop/tanseyLab/transfer_learning/transfer-learning/');rm(list=ls())
suppressMessages(require(ggplot2))
suppressMessages(require(dplyr))
target='GDSC'
data_in=read.csv('data/drug/rep-gdsc-ctd2-mean-log.csv')
data_in=data_in[,c('Drug.Name','ccle','drug_id','sample_id',
colnames(data_in)[grep(paste0('log_',target,'_published_auc_mean'),colnames(data_in))])]
id_cols=data_in[,c('Drug.Name','ccle','drug_id','sample_id')]
data_out_train=read.csv('results/2023-10-03/test_transfer/train_predictions.csv')
colnames(data_out_train)[2]='sample_id'
data_out_train=left_join(data_out_train,id_cols,by=c('sample_id','drug_id'))
data_out_test=read.csv('results/2023-10-03/test_transfer/test_predictions.csv')
colnames(data_out_test)[2]='sample_id'
data_out_test=left_join(data_out_test,id_cols,by=c('sample_id','drug_id'))
data_out=rbind(data_out_train,data_out_test);rownames(data_out)=paste0(data_out$drug_id,'_',data_out$sample_id)
data_out=data_out[paste0(data_in$drug_id,'_',data_in$sample_id),]
data_out=data_out[,c('Drug.Name','ccle','drug_id','sample_id','predictions')]
identical(paste0(data_out$drug_id,'_',data_out$sample_id),paste0(data_in$drug_id,'_',data_in$sample_id))
View(data_out)
suppressMessages(require(reshape2))
df_out=dcast(data_out,'sample_id'~'drug_id',value.var = 'predictions')
View(df_out)
df_out=dcast(data_out,sample_id ~ drug_id,value.var = 'predictions')
View(df_out)
df_in=dcast(data_in,sample_id ~ drug_id,value.var = paste0('log_',target,'_published_auc_mean'))
View(df_in)
3318/16588
tolower('CHICKEN PESTO PARM')
View(data_in)
View(df_in)
